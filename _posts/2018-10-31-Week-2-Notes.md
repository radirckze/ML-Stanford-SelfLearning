---
layout: post
title:  "Week-2 notes."
author: "Ravi Dirckze"
---

# Week 2: learning Linear Regression with multiple variables

**Octave tutorial related to the Octave/Matlab Tutorials section of Week 2 coursework are located in the OctTutorials section**

Once again I have created a training set data from a know function function so I can validate my work. The training set is one that has 2 features. The training set is based on the the formula:

 Y = 1 + 0.2X1 + 0.4X2')
 
Graph2Data.txt contains the training set data in the form x1, x2, y. There are 21 datasets.  
(Note-1: values.csv is the training dataset in csv format so you can use a spreadsheet to validate/visualize pratial results, if necessary).  
(Note-2: I used the debugGDAlgorithm scrip to debug the gradient descent algorithm)


### Part 1 
Load the training set and graph the data. (Note: the grahing part has been commented out)

### Part 2
Guess at a set of thetas (i.e., theta0, theta1, theta2). This is our initial hypothesis. Graph the hypothesis against the training set just for kicks.  

### Part 3
Apply multi-variale linear regression to the training set.  
(First, pick a value for alpha and test it. For example if alpah is too large it could cause the algorithm to regress too fast and fail in a few steps. Note: I have commented out this code.)

gradientDescentMF is a version of gradient descent that works for a multi-feature training set (i.e multi variable version).  
Also note that this script implements a ***vectorized*** version of gradient descent. An explanation of the vectorized implementation is provided in the script.

**Some interesting observations** 

The gradient descent algorithm is terminated when the difference between the estimated values (i.e., the estimated y) and the actual values (i.e., the y values from the trainint set) is negligable, and therefore, we assume that the algorithm has converged  on the actual theta values.

  
The choice of the initial theta values (our hypothesis) and the point at which we consider the gradient descent has converged provides some intering facts.

When you choose theta0 = 0.5, theta1 = 0.5 and theta2 = 0.2 as the hypothesis, and terminate the loop when the total difference in values between the predicted y and acutla y is less that 0.00001, the algorithm will return the following values:  
theta0 = 0.499256, Theta1 = 0.465896, Theta2 = 0.174834  
Note that when you look at the graph, these theta values provde a better estimation than the hypothesis, but the resulting formula  
Y = 0.499256 + 0.465896 * X1 + 0.174834 * X2  
is nothing like the acutal formular. 
However, when you run the loop until the difference is less than 0.000000000001, the algorithm will return the following values (after some 200K runs and a *long* time):  
Theta0 = 0.991958, Theta1 = 0.211718, Theta2 = 0.384435  
Note that these values are very close to the actual values, and therefore, we can conclude that the algorithm is working and will eventuall converge on the actual values. 

However, if you choose theta0 = 1, theta1 = 1 and theta2 = 1 as the hypothesis, and terminate when the difference between the predicted and actual y's is less than 0.000000000001, the algorithm will return the following values after only 36K loops:  
Theta0 = 0.999249, Theta1 = 0.200877, Theta2 = 0.398892

***Question:*** how to do pick the hypothesis, and how do you determine when to terminate the gradient descent algorithm?
 

### Part 4 
Use the normal equation method just for comparison. (Note: for a training set with such a small dataset the normal euation works ***much*** faster. 

### Part 5
normlize featue data (i.e., X) and rerun gradient descent on the normalized data. Validate the results.  
(Note: gradient descent on the normalized data takes a long time (couple of minutes). 

