---
layout: post
title:  "Week-3 notes."
author: "Ravi Dirckze"
---

# Lecture Notes - Logistic Regression

This contains key notes from video lectures from week 3 *See paper notes for detailed lecture notes.*

Recall:  
Training example => [m,n] matrix where m is the number of examples and n is the number of features.  
x<sub>j</sub><sup>(i)</sup> => the jth feature of the ith training example. 

Logistic regression is used for cassification propblems. (Due to limitations we cannot use linear regression for categorization problems.)

Binary Classification:   
y in {0, 1}.  0 is the Negative Class, 1 is Positive class.  

**Logistic Regression**  

(Recall for Linear Regression, the hypothesis is: h<sub>&theta;</sub>(x) = &theta;<sup>T</sup>X )

For logistic regression (LR) we use the sigmoid function (a.k.a logistic function) which is:  
g(z) = 1 / (1 + e<sup>-z</sup>)  
A key property of the lositic function is the following:  
0<= g(z) <= 1 for all real numbers z.
So the hypothesis will predict values between 0 and 1.
(Note: See https://en.wikipedia.org/wiki/Sigmoid_function for more details on the logistic regression function)  
Also, note that 0<= g(z) < 0.5 for all z < 0 and 0.5 < g(z) <= 1 for all z > 0 and. (We take advantage of this fact later.)

LR h<sub>&theta;</sub>(x) = g(&theta;<sup>T</sup>X) =  1 / (1 + e<sup>-&theta;<sup>T</sup>X</sup>)  

**Interpretation of h<sub>&theta;</sub>(x)** 

When h<sub>&theta;</sub>(x) = 0.7 =>  
P(y=1) is 70% and P(y=0) is 30%

**Decision Boundary**

Since 0 <= 1 / (1 + e<sup>-z</sup>) <= 1, we predict:  
y = 1 when g(z) >= 0.5 and  
y = 0 when g(z) < 0.5 

As h<sub>&theta;</sub>(x) = g(&theta;<sup>T</sup>X), this equates to  
y = 1 when h<sub>&theta;</sub>(x) = g(&theta;<sup>T</sup>X) >= 0.5, which is **&theta;<sup>T</sup>X >= 0**   
... and  
y = 0 when **&theta;<sup>T</sup>X < 0**  

*Note* that the decision boundary is when **&theta;<sup>T</sup>X = 0**. This is the point at which the decision changes from 0 to 1, that is our prediction y changes from 0 to 1.  
(We will use this later to plot the decision boundary.)

**Cost Function**  

The cost function J(&theta;) for linear regression can be written as:  
J(&theta;) = 1/m ( Sum ( 1/2 * (h<sub>&theta;</sub>(x) -y )<sup>2</sup> ) )  
where h<sub>&theta;</sub>(x) = g(&theta;<sup>T</sup>X)

J(&theta;) is *not* a convex graph so gradient descent would not work. So need to choose a differnt cost function that works with a J(&theta;) that uses the sigmoid function. 

So, for logistic regression the cost function used is:  

Cost(h<sub>&theta;</sub>(x), y) =  
&nbsp;&nbsp;&nbsp; -log(h<sub>&theta;</sub>(x)) if y=1  
&nbsp;&nbsp;&nbsp; -log(1 - h<sub>&theta;</sub>(x)) if y=0

Why use the above function?   
Take a look at the log function https://en.wikipedia.org/wiki/Logarithm.  

Note that 0 <= h<sub>&theta;</sub>(x) <= 1 so we are only interested in the portion 0 <= x <= 1 (log base 10)   
Notice that log(1) = 0 and log(0) = -infinity  

So when y=1 and h<sub>&theta;</sub>(x) = 1 =>   
Cost(h<sub>&theta;</sub>(x), y) = -log(1) = 0  
When y=1 and h<sub>&theta;</sub>(x) = 0 =>   
Cost(h<sub>&theta;</sub>(x), y) = -log(0) = infinity.  

Similarly when y=0 and h<sub>&theta;</sub>(x) = 0, cost is 0, ...

So basically this cost function will give us values between 0 and infinity based on how close our prediction is.  

We can compress the cost function as follows:  

Cost(h<sub>&theta;</sub>(x), y) = -y log(h<sub>&theta;</sub>(x)) - (1-y) log(1 - h<sub>&theta;</sub>(x)) 

Note that when y=0 the first terms is 0, and when y=1 the second term is 0.  As such this is equivalent to the original cost function.

So, the **cost function for all training sets** is:

J(&theta;) = -1/m * SUM ( y log(h<sub>&theta;</sub>(x)) + (1-y) log(1 - h<sub>&theta;</sub>(x)) )  
(*Note*: we have move the - sign to the outside)

**Solving the cost function**

Now that we have a cost function that is convex, we can use gradient descent to solve for the optimal &theta; 

*Gradient descent:*  
Repeat {  
&theta;<sub>j</sub> := &theta;<sub>j</sub> - &alpha; *d*/*d&theta;<sub>j</sub>* *J(&theta;)  
}

The partial derivative of  *d*/*d&theta;<sub>j</sub>* *J(&theta;)*  is out of scope for this course.
  
*Note* For a function the **partial derivative** is the rate of change with respect to a *single variable* with the others held constant. So for z=f(x,y), the partial derivative *d*z/*d*x is the rate of change of z with restpect to x keeping y constant.  
The **gradient represents** the rate of change of a given point in all directions. 

The gradient for the jth element is give below without proof:  
*d*/*d&theta;<sub>j</sub>* J(&theta;) = 1/m * (Sum( (h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) *  x<sub>j</sub><sup>(i)</sup> for i=1..m)

Applying the above to our gradient descent algorithm we arrive at:  
Repeat {  
&theta;<sub>j</sub> :=  &theta;<sub>j</sub> - &alpha;/m ( Sum( (h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) *  x<sub>j</sub><sup>(i)</sup> for i=1..m)  
}

*Vectorized Implementation of Gradient Descent*

Viasualizing Sum ( (h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) * x<sub>j</sub><sup>(i)</sup> for i=1..m)

h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup> for i=1..m => [m,1]  
As such, let h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup> for i=1..m => K such that K = [k<sub>1</sub>; k<sub>2</sub>; ...; k<sub>m</sub>]   
Then for &theta;<sub>j</sub>,  h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) *  x<sub>j</sub><sup>(i)</sup> for i=1..m is:  
k<sub>1</sub> * [..., x<sub>j</sub><sup>(1)</sup>, ...]    
k<sub>2</sub> * [..., x<sub>j</sub><sup>(2)</sup>, ...]  
...  
k<sub>m</sub> * [..., x<sub>j</sub><sup>(m)</sup>, ...]  

As such, ( (h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) *  x<sub>j</sub><sup>(i)</sup> for i=1..m) for j=1..n+1 can be vectorized as:  
X<sup>T</sup> * ( (h<sub>&theta;</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) *  x<sub>j</sub><sup>(i)</sup> for i=1..m)  
which is:  
X<sup>T</sup> * K => an [n+1*1] matrix


Given the above the vectorized implementation of:  
Repeat {  
&theta;<sub>j</sub> := &theta;<sub>j</sub> - &alpha; *d*/*d&theta;<sub>j</sub>* *J(&theta;)  
}

is: 

&theta; := &theta; - &alpha;/m (X<sup>T</sup> * K)  

which is:

&theta; := &theta; - &alpha;/m (X<sup>T</sup> * (g(...)- y))  

**Plotting Decision Boundary**

As noted above the decision boundary is when &theta;<sup>T</sup>X = 0.  
Assuming that the data has two features and that the function is linear, we arive at:  
&theta;<sup>T</sup>X => &theta;<sub>0</sub>x<sub>0</sub> + &theta;<sub>1</sub>x<sub>1</sub> + &theta;<sub>2</sub>x<sub>2</sub> where x<sub>0</sub> = 1.  
As such, the decision boundary is:  
&theta;<sub>0</sub> + &theta;<sub>1</sub>x<sub>1</sub> + &theta;<sub>2</sub>x<sub>2</sub> = 0.

Given &theta; we can graph the decision boundary by randomly picking 2 values for feature 1 (i.e., x<sub>1,1</sub> and x<sub>1,2</sub>) and calculating the corresponding values for feature 2 (i.e., x<sub>2,1</sub> and x<sub>2,2</sub>) as follows:

x<sub>2</sub> = (-1 / &theta;<sub>2</sub>) *  (&theta;<sub>1</sub>x<sub>1</sub> + &theta;<sub>0</sub>)

The line from (x<sub>1,1</sub>,x<sub>2,1</sub>) to (x<sub>1,2</sub>,x<sub>2,2</sub>) is the decision boundary, that is, at any point on that line &theta;<sup>T</sup>X = 0. 

## PART 2: Regularized Logistic Regression

In order to generate a better predictor, we can add more features (that is, higher order terms, for example x<sub>1</sub><sup>2</sup>, x<sub>1</sub>x<sub>2</sub>, x<sub>2</sub><sup>2</sup>, etc).  
Note that, as we add more features we usually get a better predictor but this also leads to overfitting.  

**Overfitting:** (a.k.a. high variance) can be thought of as a precise predictor for the sample set but not necessarily for the real world.  
**Underfitting:** (a.k.a high bias) can be thought of a simplified predictor that is not sufficiently accurate to be a good predictor. 

There are two main options to address the issue of overfitting:

1 - Reduce the number of features:

Manually select which features to keep.
Use a model selection algorithm (studied later in the course).

2 - Regularization

Keep all the features, but reduce the magnitude of parameters &theta;<sub>j</sub>. Regularization works well when we have a lot of slightly useful features. (How to do this is discussed in the course but is skipped in these notes.)

## Multiclass Classification

To solve a multiclass classification problem using logistic regression use multiple one-vs-all logistic regression models.



